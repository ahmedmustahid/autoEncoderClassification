{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd30c3db-e780-47d0-8c0a-b5f6a52f82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models,transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.autograd import Function\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336734a8-1596-4d9f-9800-6125fdb7b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "zsize = 224\n",
    "batch_size = 256\n",
    "iterations =  500\n",
    "learningRate= 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c9544b-8db7-496a-90db-e2d6703f2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce052850-f095-4495-817c-7f3e04362198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5602ee7d-084b-43c7-9b4c-93190913cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f575943-e1ef-4829-b900-7b3b8490cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\t\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02a136b-2449-4ccb-aa15-d8e3c7ac7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=23):\n",
    "        self.inplanes = 64\n",
    "        super (Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)#, return_indices = True)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, 1000)\n",
    "\t#self.fc = nn.Linear(num_classes,16) \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\t\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\t\n",
    "        x = self.maxpool(x)\n",
    "\t\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d605a24-8721-4624-ada5-e117c8b86143",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(Bottleneck, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b458261-9b82-4012-8cd1-8df6afa63793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load(\"/home/ahmed/work/autoEncoderWorks/data/resnet50-19c8e357.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5581432b-8070-414a-a1fe-46861bc50be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fc = nn.Linear(2048, 48)\n",
    "#for param in encoder.parameters():\n",
    "#    param.requires_grad = False\n",
    "encoder=encoder.cuda()\n",
    "y=torch.rand(1,3,224,224)\n",
    "x=torch.rand(1,128)\n",
    "x=Variable(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483a39cc-d69e-4692-8e2b-4640bc69750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binary(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return F.relu(Variable(input.sign())).data\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output\n",
    "\n",
    "binary = Binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a44b9d2-2cad-488e-b91c-c09d9910c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Decoder,self).__init__()\n",
    "\t\tself.dfc3 = nn.Linear(zsize, 4096)\n",
    "\t\tself.bn3 = nn.BatchNorm2d(4096)\n",
    "\t\tself.dfc2 = nn.Linear(4096, 4096)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(4096)\n",
    "\t\tself.dfc1 = nn.Linear(4096,256 * 6 * 6)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(256*6*6)\n",
    "\t\tself.upsample1=nn.Upsample(scale_factor=2)\n",
    "\t\tself.dconv5 = nn.ConvTranspose2d(256, 256, 3, padding = 0)\n",
    "\t\tself.dconv4 = nn.ConvTranspose2d(256, 384, 3, padding = 1)\n",
    "\t\tself.dconv3 = nn.ConvTranspose2d(384, 192, 3, padding = 1)\n",
    "\t\tself.dconv2 = nn.ConvTranspose2d(192, 64, 5, padding = 2)\n",
    "\t\tself.dconv1 = nn.ConvTranspose2d(64, 3, 12, stride = 4, padding = 4)\n",
    "\n",
    "\tdef forward(self,x):#,i1,i2,i3):\n",
    "\t\t\n",
    "\t\tx = self.dfc3(x)\n",
    "\t\t#x = F.relu(x)\n",
    "\t\tx = F.relu(self.bn3(x))\n",
    "\t\t\n",
    "\t\tx = self.dfc2(x)\n",
    "\t\tx = F.relu(self.bn2(x))\n",
    "\t\t#x = F.relu(x)\n",
    "\t\tx = self.dfc1(x)\n",
    "\t\tx = F.relu(self.bn1(x))\n",
    "\t\t#x = F.relu(x)\n",
    "\t\t#print(x.size())\n",
    "\t\tx = x.view(batch_size,256,6,6)\n",
    "\t\t#print (x.size())\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = self.dconv5(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(self.dconv4(x))\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(self.dconv3(x))\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx = self.dconv2(x)\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx = F.relu(x)\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = self.dconv1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.sigmoid(x)\n",
    "\t\t#print x\n",
    "\t\treturn x\n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d477e4-b5e8-4399-bfac-d8cff453947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Autoencoder,self).__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tself.binary = Binary()\n",
    "\t\tself.decoder = Decoder()\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\t#x=Encoder(x)\n",
    "\t\tx = self.encoder(x)\n",
    "\t\tx = binary.apply(x)\n",
    "\t\t#print x\n",
    "\t\t#x,i2,i1 = self.binary(x)\n",
    "\t\t#x=Variable(x)\n",
    "\t\tx = self.decoder(x)\n",
    "\t\treturn x\n",
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2416c755-df7c-4dce-b31f-cb56eaceee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Classifier,self).__init__()\n",
    "\t\tself.L1 = nn.Linear(zsize,64)\n",
    "\t\tself.L2 = nn.Linear(64,32)\n",
    "\t\tself.L3 = nn.Linear(32,23)\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tx = F.relu(self.L1(x))\n",
    "\t\tx = F.relu(self.L2(x))\n",
    "\t\tx = F.log_softmax(self.L3(x))\n",
    "\t\treturn x\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78e6aaac-5374-4f5f-b23c-a6e84470e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Classification,self).__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tself.binary = Binary()\n",
    "\t\tself.classifier = Classifier()\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tx= self.encoder(x)\n",
    "\t\tx = binary.apply(x)\t\t\n",
    "\t\t#x= self.binary(x)\n",
    "\t\tx = self.classifier(x)\n",
    "\t\treturn x\n",
    "\n",
    "#print Classification()\n",
    "classification = Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25a2f65b-79ab-43ad-bbf2-d34cef3e4ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f4a97ea26d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\tautoencoder.cuda()\n",
    "\tclassification.cuda()\n",
    "\tdecoder.cuda()\n",
    "\tencoder.cuda()\n",
    "\tclassifier.cuda()\n",
    "\t#data\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0cd4378-d62b-479b-aa28-ecc2bcf826c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    pinMem = True # Flag for pinning GPU memory\n",
    "    print('GPU is available!')\n",
    "else:\n",
    "    pinMem = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "872d470a-0e40-4951-a6b1-dc1558fd6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=False)\n",
    "transform = transforms.Compose(\n",
    "\t[\n",
    "\ttransforms.Resize((224,224), interpolation= torchvision.transforms.InterpolationMode.BICUBIC),\n",
    "\ttransforms.ToTensor(),\n",
    "\t#transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "\t#transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "\t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e861d085-c73c-4cc7-9d16-f8ca96aaa710",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/home/ahmed/work/autoEncoderWorks/data\"\n",
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b1f397b-9303-4eb9-822b-ba48622f82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2755cd-96c6-4bf3-a216-631b7458c38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41dfd670-a764-4f38-8d4e-fdf2715e6489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2f5bad4-570e-4bdc-ad0e-ef5085bb1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_criterion = nn.MSELoss()\n",
    "classification_criterion = nn.NLLLoss()\n",
    "\n",
    "autoencoder_optimizer = optim.Adam(autoencoder.parameters(), lr = learningRate)\n",
    "classification_optimizer = optim.Adam(classification.parameters(), lr = learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "096e61a9-7b99-4f5d-9525-ec3fc2ddb652",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x48 and 224x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m classification_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#print(inputs.size())\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#torchvision.utils.save_image(pred.data[0:8], os.path.join('/home/deepkliv/Saket/AE_Classifier/', 'batch_%d_%d'%((epoch+1)/1,i+1) + '.jpg'))\u001b[39;00m\n\u001b[1;32m     21\u001b[0m a_loss \u001b[38;5;241m=\u001b[39m autoencoder_criterion(pred , inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/envs/autoEncoder/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mAutoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m binary\u001b[38;5;241m.\u001b[39mapply(x)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print x\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#x,i2,i1 = self.binary(x)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#x=Variable(x)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/envs/autoEncoder/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\u001b[38;5;66;03m#,i1,i2,i3):\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdfc3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \t\u001b[38;5;66;03m#x = F.relu(x)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \tx \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(x))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/envs/autoEncoder/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/envs/autoEncoder/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/envs/autoEncoder/lib/python3.9/site-packages/torch/nn/functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x48 and 224x4096)"
     ]
    }
   ],
   "source": [
    "list_a_loss = []\n",
    "list_c_loss = []\n",
    "\n",
    "#fig = plt.figure()\n",
    "for epoch in range(iterations):\n",
    "\trun_loss = 0 \n",
    "\trun_c_loss = 0\n",
    "\tautoencoder.train(True) # For training\n",
    "\tclassification.train(True)\n",
    "\tfor i,data in enumerate(train_loader):\n",
    "\t\t#print i\n",
    "\t\tinputs, labels = data\n",
    "\t\tinputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "\t\t\n",
    "\t\tautoencoder_optimizer.zero_grad()\n",
    "\t\tclassification_optimizer.zero_grad()\n",
    "\t\t#print(inputs.size())\n",
    "\t\tpred = autoencoder(inputs)\n",
    "\t\t#torchvision.utils.save_image(pred.data[0:8], os.path.join('/home/deepkliv/Saket/AE_Classifier/', 'batch_%d_%d'%((epoch+1)/1,i+1) + '.jpg'))\n",
    "\t\ta_loss = autoencoder_criterion(pred , inputs)\n",
    "\t\ta_loss.backward()\n",
    "\t\tautoencoder_optimizer.step()\n",
    "\n",
    "\t\t#print(\"efc3\", autoencoder.encoder.fc3.bias.grad)\n",
    "\t\t\n",
    "\t\tclass_pred = classification(inputs)\n",
    "\n",
    "\t\tc_loss = classification_criterion(class_pred , labels)\n",
    "\t\n",
    "\t\t#_,xxpred = torch.max(class_pred.data, 1)\n",
    "\t\t#print(\"class_pred\")\n",
    "\t\t#print(xxpred.cpu().numpy())\n",
    "\t\tc_loss.backward(retain_graph=True)\n",
    "\t\tclassification_optimizer.step()\n",
    "\t\t#encoder_optimizer.step()\n",
    "\t\t\n",
    "\t\trun_loss += a_loss.data[0]\n",
    "\t\trun_c_loss += c_loss.data[0]\n",
    "\t\t#print i\n",
    "\t\tif (i +1) % 2 == 0:\n",
    "\t\t\tprint('[%d, %5d] Autoencoder loss: %.3f Classification loss: %.3f' % (epoch + 1, i + 1 , run_loss/2 , run_c_loss/2))\n",
    "\t\t\t#print('[%d,%5d] Classification loss: %.3f' % (epoch + 1, i + 1, run_c_loss/10))\n",
    "\t\t\trun_c_loss = 0.0\n",
    "\t\t\trun_loss = 0.0\n",
    "\n",
    "\n",
    "\t\tdecoder_path = os.path.join(DATASET_PATH, 'decoder-%d.pkl' %(epoch+1))\n",
    "\t\tencoder_path = os.path.join(DATASET_PATH, 'encoder-%d.pkl' %(epoch+1))\n",
    "\t\tautoencoder_path = os.path.join(DATASET_PATH, 'autoencoder-%d.pkl' %(epoch+1))\n",
    "\t\tclassifier_path = os.path.join(DATASET_PATH, 'classifier-%d.pkl' %(epoch+1))\n",
    "\t\tclassification_path = os.path.join(DATASET_PATH,'classification-%d.pkl' %(epoch+1))\n",
    "\t\t\n",
    "\t\ttorch.save(decoder.state_dict(), decoder_path)\n",
    "\t\ttorch.save(encoder.state_dict(), encoder_path)\n",
    "\t\ttorch.save(autoencoder.state_dict(), autoencoder_path)\n",
    "\t\ttorch.save(classifier.state_dict(), classifier_path)\n",
    "\t\ttorch.save(classification.state_dict(), classification_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc6989-0254-43f8-a1f4-6143c69c2e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
